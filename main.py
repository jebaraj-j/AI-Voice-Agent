import os
import speech_recognition as sr
import vertexai
from vertexai.preview.generative_models import GenerativeModel
from google.cloud import speech
import pyttsx3
from vertexai.preview.generative_models import SafetySetting
from google.api_core.exceptions import GoogleAPICallError, RetryError
import time

# ‚úÖ Set the service account key
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "voice_ai_key.json"

# ‚úÖ Initialize Vertex AI (Gemini API)
vertexai.init(
    project="abstract-arbor-454701-m0",  # Your GCP project ID
    location="us-central1"
)
print("‚úÖ Gemini API connected successfully!")

# ‚úÖ Configure the Gemini model
model = GenerativeModel(model_name="gemini-1.5-pro-002")

# üéØ Generation Configuration
generation_config = {
    "max_output_tokens": 4000,
    "temperature": 0.7,
    "top_p": 0.95,
    "seed": 0,
}

# üîí Safety settings
safety_settings = [
    SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold=1),
    SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold=1),
    SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold=1),
    SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold=1)
]

# ‚úÖ Store conversation history
conversation_history = []


# üéôÔ∏è **Function to listen and recognize voice**
def listen():
    """Listen and recognize voice using Google Cloud STT."""
    recognizer = sr.Recognizer()
    client = speech.SpeechClient()

    with sr.Microphone() as source:
        print("üéôÔ∏è Listening... (Speak clearly)")
        recognizer.adjust_for_ambient_noise(source, duration=1)  # Noise reduction

        try:
            audio = recognizer.listen(source, timeout=15, phrase_time_limit=15)
            print("üõ†Ô∏è Recognizing...")

            # Convert to WAV format
            audio_data = audio.get_wav_data()

            # ‚úÖ Google Cloud STT configuration (Improved accuracy)
            audio_file = speech.RecognitionAudio(content=audio_data)

            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=44100,   # Match sample rate
                language_code="en-US",      # English only
                model="latest_long",        # Use latest model for better accuracy
                enable_automatic_punctuation=True  # Better sentence formatting
            )

            response = client.recognize(config=config, audio=audio_file)

            if response.results:
                text = response.results[0].alternatives[0].transcript
                print(f"‚úÖ You said: {text}")
                return text
            else:
                print("‚ùå No response recognized.")
                return ""

        except sr.UnknownValueError:
            print("‚ùå Could not understand the audio.")
            return ""

        except sr.RequestError:
            print("‚ùå Could not request results.")
            return ""

        except sr.WaitTimeoutError:
            print("‚è±Ô∏è No speech detected. Try again.")
            return ""

        except Exception as e:
            print(f"‚ùå Error: {e}")
            return ""


# ü§ñ **Function to generate AI response with retry and rate limiting**
def get_response(user_input, max_retries=3, retry_delay=2):
    """Generate AI response with Gemini API and retry on 429 errors."""
    global conversation_history
    print(f"ü§ñ Generating AI Response for: {user_input}")

    retries = 0

    while retries < max_retries:
        try:
            # ‚úÖ Add rate-limiting delay
            time.sleep(1.5)

            # ‚úÖ Include conversation history
            full_prompt = "\n".join(conversation_history + [f"You: {user_input}"])

            responses = model.generate_content(
                [full_prompt],
                generation_config=generation_config,
                safety_settings=safety_settings
            )

            message = responses.text.replace('*', '')
            print(f"‚úÖ AI Response: {message}")

            # ‚úÖ Store conversation history (last 10 exchanges)
            conversation_history.append(f"You: {user_input}")
            conversation_history.append(f"AI: {message}")
            conversation_history = conversation_history[-10:]

            return message

        except GoogleAPICallError as e:
            if "Resource exhausted" in str(e):
                retries += 1
                print(f"üîÑ Retrying... Attempt {retries}/{max_retries}")
                time.sleep(retry_delay)
            else:
                print(f"‚ùå API Error: {e}")
                return "I'm having trouble connecting right now. Please try again later."

        except Exception as e:
            print(f"‚ùå Unknown Error: {e}")
            return "Something went wrong. Please try again."

    print("‚ùå Max retries reached. Try again later.")
    return "I'm having trouble connecting. Please try again later."


# üîä **Function to convert text to speech with standard voice**
def speak(text):
    """Convert text to speech with a consistent voice using pyttsx3."""
    try:
        engine = pyttsx3.init()

        # ‚úÖ Set a consistent voice
        voices = engine.getProperty('voices')

        # Choose a specific voice for consistency
        engine.setProperty('voice', voices[1].id)  # Female voice (index may vary)

        # ‚úÖ Set the speed and volume for standardization
        engine.setProperty('rate', 180)  # Normal speaking rate
        engine.setProperty('volume', 1.0)  # Max volume

        print("üîä Speaking...")
        engine.say(text)
        engine.runAndWait()

    except Exception as e:
        print(f"‚ùå Error in TTS: {e}")


# üöÄ **Main function**
def main():
    print("üöÄ Voice AI Assistant Running...")

    while True:
        user_input = listen()

        if user_input and "exit" in user_input.lower():
            print("üëã Exiting...")
            break

        if user_input:
            response = get_response(user_input)
            speak(response)


# ‚úÖ Run the assistant
if __name__ == "__main__":
    main()
